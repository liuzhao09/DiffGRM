# DIFF_GRM Model Configuration
model: DIFF_GRM

# SID Configuration
n_digit: 4
codebook_size: 256
share_embeddings: true

# Model Architecture
encoder_n_layer: 4
decoder_n_layer: 4
n_head: 8
n_embd: 448
n_inner: 1024
dropout: 0.1
embd_pdrop: 0.1
attn_pdrop: 0.1
resid_pdrop: 0.1

# Generation
beam_size: 10
max_generation_len: 4

# Diffusion Configuration
# 新方式：多概率掩码配置（优先级更高）
mask_probs: "1.0,0.75,0.5,0.25"    # 4种不同的掩码概率，对应4个视图
# 旧方式：单一掩码配置（作为备选）
mask_prob: 0.5                     # 训练时的掩码概率（仅在未设置mask_probs时使用）
augment_factor: 4                   # 数据增强倍数（仅在未设置mask_probs时使用）
max_history_len: 50                 # 历史序列最大长度

# Sentence Embedding (for SID generation)
metadata: sentence
sent_emb_model: sentence-transformers/sentence-t5-base
sent_emb_dim: 768
sent_emb_pca: 128
sent_emb_batch_size: 512

# OPQ Configuration
opq_use_gpu: False
opq_gpu_id: 0
faiss_omp_num_threads: 32

# Training
temperature: 0.07
train_batch_size: 256
eval_batch_size: 16
lr: 0.0003
weight_decay: 0.0
warmup_steps: 10000
epochs: 150
max_grad_norm: 1.0
eval_interval: 5  # 每5轮评估一次，而不是每轮都评估
eval_start_epoch: 20  # 从第20个epoch开始评估
patience: 4       # 4次评估无提升就早停（约20轮，因为5x4=20）

# Evaluation
topk: [5,10]
metrics: [ndcg,recall]
val_metric: weighted_score  # 使用加权综合指标：NDCG@10 * 0.6 + RECALL@10 * 0.4 