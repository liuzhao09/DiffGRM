# DIFF_GRM Model Configuration
model: DIFF_GRM

# SID Configuration
n_digit: 4
codebook_size: 256
share_embeddings: true

# Model Architecture
encoder_n_layer: 2
decoder_n_layer: 2
n_head: 4
n_embd: 256
n_inner: 512
dropout: 0.1
embd_pdrop: 0.1
attn_pdrop: 0.1
resid_pdrop: 0.1

# Output Layer Configuration
share_decoder_output_embedding: true   # ä½¿ç”¨å…±äº«embedding dot-productï¼Œfalseæ—¶å›é€€åˆ°ç‹¬ç«‹Linear

# â”€â”€â”€ æ–°å¢ï¼šè¦åœ¨éªŒè¯/æµ‹è¯•é˜¶æ®µè·‘çš„ beam æ¨¡å¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
beam_search_modes: ["confidence", "random"]   # é¡ºåºå†³å®šæ—¥å¿—å±•ç¤ºé¡ºåº
# å¦‚æœåªæƒ³å¶å°”è·‘ randomï¼ŒæŠŠå®ƒåˆ æ‰å³å¯

# â”€â”€â”€ æ–°å¢ï¼šrandom-beam çš„é‡‡æ ·è¶…å‚ï¼ˆç¤ºä¾‹ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
random_beam:
  beam_act: 128        # ğŸ‘ˆ ä½ è¦çš„ "random_beam_size"
  beam_max: 128
  seed: 42            # ä¿ç•™ï¼Œç”¨æ¥å›ºå®šéšæœºåˆ—é¡ºåº

# Generation - å‘é‡åŒ–Beam Searché…ç½®ï¼ˆç»Ÿä¸€ç®¡ç†ï¼‰
vectorized_beam_search:
  # === é€šç”¨é…ç½® ===
  top_k_final: 10                  # æœ€ç»ˆè¿”å›çš„åºåˆ—æ•°é‡
  neg_inf_fp32: -1000000000.0      # FP32è´Ÿæ— ç©·å€¼ (-1e9)
  neg_inf_fp16: -65504.0           # FP16è´Ÿæ— ç©·å€¼
  dedup_strategy: simple            # å»é‡ç­–ç•¥ï¼šsimple | weighted | none

  # === split-specificé…ç½® ===
  # éªŒè¯æ—¶ä½¿ç”¨è¾ƒå°çš„beam sizeï¼Œä¿è¯é€Ÿåº¦
  val:     {beam_act: 32,  beam_max: 32}
  # æµ‹è¯•æ—¶ä½¿ç”¨è¾ƒå¤§çš„beam sizeï¼Œä¿è¯ç²¾åº¦
  test:    {beam_act: 256, beam_max: 256}
  
  # â†“å¯ç•™å¯åˆ ï¼Œçº¯å…¼å®¹æ—§ä»£ç 
  beam_act: 32
  beam_max: 32

# å…¼å®¹æ€§å‚æ•°ï¼ˆä¿ç•™ç”¨äºæ—§ä»£ç ï¼‰
beam_size: 10
max_generation_len: 4

# Diffusion Configuration
# === Mask-Augment ç›¸å…³ ===
masking_strategy: random      # random | sequential
sequential_steps: auto        # auto(=n_digit) æˆ– 1~n_digit çš„æ•´æ•°ï¼ˆå»ºè®®â‰¤n_digit-1ä»¥è·³è¿‡å…¨æ­å¼€è§†å›¾ï¼‰
sequential_paths: 1           # æ–°å¢â€”â€”åŒä¸€ä¸ªæ ·æœ¬å¹¶è¡Œå¤šå°‘æ¡éšæœºè·¯å¾„ï¼ˆä»…sequentialæ¨¡å¼æœ‰æ•ˆï¼‰
# æ–°æ–¹å¼ï¼šå¤šæ¦‚ç‡æ©ç é…ç½®ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
mask_probs: "1.0,0.75,0.5,0.25"    # 4ç§ä¸åŒçš„æ©ç æ¦‚ç‡ï¼Œå¯¹åº”4ä¸ªè§†å›¾
# æ—§æ–¹å¼ï¼šå•ä¸€æ©ç é…ç½®ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
mask_prob: 0.5                     # è®­ç»ƒæ—¶çš„æ©ç æ¦‚ç‡ï¼ˆä»…åœ¨æœªè®¾ç½®mask_probsæ—¶ä½¿ç”¨ï¼‰
augment_factor: 4                   # æ•°æ®å¢å¼ºå€æ•°ï¼ˆä»…åœ¨æœªè®¾ç½®mask_probsæ—¶ä½¿ç”¨ï¼‰
max_history_len: 50                 # å†å²åºåˆ—æœ€å¤§é•¿åº¦

# Data Split Configuration
split: leave_one_out          # æ•°æ®åˆ’åˆ†ç­–ç•¥ï¼šleave_one_out | last_out
train_sliding: false          # æ˜¯å¦å¯¹trainåšæ»‘çª—æ‰©å……ï¼ˆtrue=æ»‘çª—ï¼Œfalse=ç»å…¸leave-one-outï¼‰
min_hist_len: 2               # æ»‘çª—æœ€çŸ­historyé•¿åº¦ï¼ˆå«labelå‰çš„åºåˆ—é•¿åº¦ï¼‰
max_hist_len: 50              # æ»‘çª—æœ€é•¿historyé•¿åº¦ï¼ˆä¸max_history_lenå¯¹é½ï¼‰

# Sentence Embedding (for SID generation)
metadata: sentence
sent_emb_model: sentence-transformers/sentence-t5-base
sent_emb_dim: 768
sent_emb_pca: 256
sent_emb_batch_size: 512

# OPQ Configuration
opq_use_gpu: False
opq_gpu_id: 0
faiss_omp_num_threads: 32
force_regenerate_opq: true  # æ˜¯å¦å¼ºåˆ¶é‡æ–°ç”ŸæˆOPQé‡åŒ–ç»“æœï¼ˆå³ä½¿å·²å­˜åœ¨ï¼‰
disable_opq: false  # æ˜¯å¦ç¦ç”¨OPQï¼Œä½¿ç”¨çº¯PQé‡åŒ–

# Training
temperature: 0.07
train_batch_size: 256
eval_batch_size: 32
lr: 0.0003
weight_decay: 0.0
warmup_steps: 10000
epochs: 100
max_grad_norm: 1.0
label_smoothing: 0.1


# Evaluation
eval_interval: 2  # æ¯xxè½®è¯„ä¼°ä¸€æ¬¡ï¼Œè€Œä¸æ˜¯æ¯è½®éƒ½è¯„ä¼°
eval_start_epoch: 20  # ä»ç¬¬xxä¸ªepochå¼€å§‹è¯„ä¼°
patience: 5       # xxæ¬¡è¯„ä¼°æ— æå‡å°±æ—©åœ
topk: [5,10]
metrics: [ndcg,recall]
val_metric: weighted_score  # ä½¿ç”¨åŠ æƒç»¼åˆæŒ‡æ ‡ï¼šweighted_score = 0.8 * ndcg_10 + 0.2 * recall_10