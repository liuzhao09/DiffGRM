# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.

# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.

import torch
import numpy as np


class AR_GRMEvaluator:
    """
    AR_GRM æ¨¡å‹çš„è¯„ä¼°å™¨ï¼ˆé¡ºåºè‡ªå›å½’ beam-search è¾“å‡ºï¼‰
    """
    def __init__(self, config, tokenizer):
        self.config = config
        self.tokenizer = tokenizer
        self.metric2func = {
            'recall': self.recall_at_k,
            'ndcg': self.ndcg_at_k
        }

        self.pad_token = self.tokenizer.pad_token
        self.maxk = max(config['topk'])
        
        # ä»…ç»Ÿè®¡æ¯ä¸ª batch çš„ Top-10 åˆæ³•ç‡
        self.batch_legal_at10 = []
        
        # è°ƒè¯•ä¿¡æ¯ï¼šç¡®è®¤ä½¿ç”¨äº†DIFF_GRMEvaluator
        print(f'>> Using evaluator = {self.__class__.__name__} (AR beam)')
        print(f'>> Recall: any() æŒ‰é¦–æ¬¡å‘½ä¸­è®¡åˆ†')
        print(f'>> NDCG: first-hit-only è®¡ç®—')



    def calculate_pos_index(self, preds, labels):
        """
        è®¡ç®—é¢„æµ‹ç»“æœä¸çœŸæ ‡ç­¾çš„åŒ¹é…æƒ…å†µï¼ˆbeam searchå·²ä¿è¯åˆæ³•æ€§ï¼‰
        
        Args:
            preds: (batch_size, maxk, n_digit) - ç”Ÿæˆçš„SIDåºåˆ—ï¼ˆå·²è¿‡æ»¤ä¸ºåˆæ³•ï¼‰
            labels: (batch_size, n_digit) - çœŸæ ‡ç­¾åºåˆ—
        
        Returns:
            pos_index: (batch_size, maxk) - æ¯ä¸ªä½ç½®æ˜¯å¦åŒ¹é…çœŸæ ‡ç­¾
        """
        preds = preds.detach().cpu()
        labels = labels.detach().cpu()
        
        B, maxk, n_digit = preds.shape
        
        # ğŸš€ ç®€åŒ–ï¼šbeam searchå·²ä¿è¯è¿”å›çš„åºåˆ—éƒ½æ˜¯åˆæ³•çš„
        # ç›´æ¥è®¡ç®—åŒ¹é…æƒ…å†µï¼Œæ— éœ€å†è¿‡æ»¤
        pos_index = torch.zeros((B, maxk), dtype=torch.bool)
        
        for i in range(B):
            # è·å–çœŸæ ‡ç­¾
            cur_label = labels[i].tolist()  # [n_digit]
            
            for j in range(maxk):
                # è·å–é¢„æµ‹åºåˆ—
                cur_pred = preds[i, j].tolist()  # [n_digit]
                
                # æ¯”è¾ƒcodebook IDsï¼ˆ0-255èŒƒå›´ï¼‰
                if cur_pred == cur_label:
                    pos_index[i, j] = True
                    break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…å°±åœæ­¢ï¼Œé¿å…é‡å¤è®¡åˆ†
        
        return pos_index

    def recall_at_k(self, pos_index, k):
        """è®¡ç®—Recall@kï¼ˆä¿®å¤ï¼šé‡å¤å‘½ä¸­åªè®¡1åˆ†ï¼‰"""
        # pos_index: (batch_size, maxk) - å·²ç»è¿‡æ»¤ä¸ºåˆæ³•åºåˆ—
        # ä¿®å¤ï¼šä½¿ç”¨any()é¿å…é‡å¤è®¡åˆ†ï¼Œåªè¦top-kä¸­æœ‰â‰¥1ä¸ªåŒ¹é…å°±å¾—1åˆ†
        return pos_index[:, :k].any(dim=1).cpu().float()

    def ndcg_at_k(self, pos_index, k):
        """è®¡ç®—NDCG@kï¼ˆä¿®å¤ï¼šé‡å¤å‘½ä¸­åªè®¡ç¬¬ä¸€æ¬¡çš„DCGï¼‰"""
        # pos_index: (batch_size, maxk) - å·²ç»è¿‡æ»¤ä¸ºåˆæ³•åºåˆ—
        batch_size, maxk = pos_index.shape
        device = pos_index.device
        
        # åˆ›å»ºrankæƒé‡ï¼š1/log2(rank+1)
        ranks = torch.arange(1, maxk + 1, device=device).float()
        dcg_weights = 1.0 / torch.log2(ranks + 1)
        
        # ä¿®å¤ï¼šåªè®¡ç®—ç¬¬ä¸€ä¸ªåŒ¹é…ä½ç½®çš„DCGï¼Œé¿å…é‡å¤è®¡åˆ†ï¼ˆå‘é‡åŒ–å®ç°ï¼‰
        # åˆ›å»ºä½ç½®ç´¢å¼•çŸ©é˜µ
        position_matrix = torch.arange(maxk, device=device).expand(batch_size, -1)
        
        # æ‰¾åˆ°æ¯ä¸ªæ ·æœ¬ç¬¬ä¸€ä¸ªåŒ¹é…çš„ä½ç½®ï¼ˆå‘é‡åŒ–ï¼‰
        # å°†éåŒ¹é…ä½ç½®è®¾ä¸ºä¸€ä¸ªå¾ˆå¤§çš„æ•°ï¼Œè¿™æ ·minæ“ä½œä¼šå¿½ç•¥å®ƒä»¬
        masked_positions = torch.where(pos_index, position_matrix, torch.full_like(position_matrix, maxk))
        first_hit_positions = masked_positions.min(dim=1).values  # [batch_size]
        
        # è®¡ç®—DCGï¼šåªæœ‰åœ¨top-kå†…ä¸”æœ‰åŒ¹é…æ—¶æ‰å¾—åˆ†
        # ä¿®å¤ç´¢å¼•è¶Šç•Œé—®é¢˜ï¼šç¡®ä¿onlyçœŸæ­£æœ‰åŒ¹é…ä¸”åœ¨top-kå†…çš„æ ·æœ¬æ‰è®¡åˆ†
        has_hit = first_hit_positions < maxk  # æ˜¯å¦æœ‰åŒ¹é…
        in_topk = first_hit_positions < k  # åŒ¹é…æ˜¯å¦åœ¨top-kå†…
        valid_mask = has_hit & in_topk  # æ—¢æœ‰åŒ¹é…åˆåœ¨top-kå†…
        
        # å®‰å…¨çš„ç´¢å¼•è®¿é—®ï¼šå…ˆé™åˆ¶ç´¢å¼•èŒƒå›´ï¼Œå†è®¡ç®—å¾—åˆ†
        safe_positions = torch.clamp(first_hit_positions, 0, maxk - 1)
        dcg_scores = torch.where(valid_mask, dcg_weights[safe_positions], torch.tensor(0.0, device=device))
        
        # å¯¹äºå•æ ‡ç­¾æ¨èä»»åŠ¡ï¼ŒIDCG=1.0ï¼Œæ‰€ä»¥DCGå°±æ˜¯NDCG
        return dcg_scores.cpu().float()

    def _dup_ratio_per_user(self, preds, k=10):
        """
        è®¡ç®—ä¸€ä¸ª batch å†…"ç”¨æˆ·å†…éƒ¨"çš„é‡å¤ç‡ã€‚
        preds: [B, maxk, n_digit]ï¼ˆå·²ä¿è¯ maxk â‰¥ kï¼‰
        è¿”å›:  [B] æ¯ä¸ªç”¨æˆ·è‡ªå·±çš„é‡å¤ç‡
        """
        B, _, n_digit = preds.shape
        dup_ratios = []

        for b in range(B):
            # ä»…å–å‰ k æ¡
            seqs = preds[b, :k]                       # [k, n_digit]
            k_seqs = [tuple(s.tolist()) for s in seqs]
            unique_cnt = len(set(k_seqs))
            dup_ratios.append(1 - unique_cnt / k)     # in [0,1]

        return torch.tensor(dup_ratios, dtype=torch.float32)

    def calculate_weighted_score(self, preds, labels):
        """
        è®¡ç®—åŠ æƒç»¼åˆåˆ†æ•°ï¼šNDCG@10 * 0.8 + RECALL@10 * 0.2
        
        Args:
            preds: (batch_size, beam_size, n_digit) - ç”Ÿæˆçš„SIDåºåˆ—
            labels: (batch_size, n_digit) - çœŸæ ‡ç­¾åºåˆ—
        
        Returns:
            weighted_score: åŠ æƒç»¼åˆåˆ†æ•°
        """
        pos_index = self.calculate_pos_index(preds, labels)
        
        # è®¡ç®—NDCG@10
        ndcg_10 = self.ndcg_at_k(pos_index, k=10)
        
        # è®¡ç®—RECALL@10
        recall_10 = self.recall_at_k(pos_index, k=10)
        
        # è®¡ç®—åŠ æƒåˆ†æ•°ï¼šNDCG@10 * 0.8 + RECALL@10 * 0.2
        weighted_score = 0.8 * ndcg_10 + 0.2 * recall_10
        
        return weighted_score

    def calculate_metrics(self, preds, labels, suffix=""):
        """è®¡ç®—æ‰€æœ‰æŒ‡æ ‡"""
        results = {}
        pos_index = self.calculate_pos_index(preds, labels)
        
        # ---------- ä»…ç»Ÿè®¡ Top-10 åˆæ³•ç‡ ----------
        B, maxk, n_digit = preds.shape
        K = min(10, maxk)
        legal_mask = []
        for b in range(B):
            cnt = 0
            for j in range(K):
                if self.tokenizer.codebooks_to_item_id(preds[b, j].tolist()) is not None:
                    cnt += 1
            legal_mask.append(cnt / float(K))
        legal_at10 = torch.tensor(legal_mask, dtype=torch.float32)
        results['legal@10'] = legal_at10
        self.batch_legal_at10.append(legal_at10.mean().item())
        
        for metric in self.config['metrics']:
            for k in self.config['topk']:
                results[f"{metric}@{k}{suffix}"] = self.metric2func[metric](pos_index, k)
        
        # æ·»åŠ åŠ æƒç»¼åˆåˆ†æ•°ï¼ˆåªåœ¨confidenceæ¨¡å¼ä¸‹è®¡ç®—ï¼‰
        if suffix == "":  # ä»…confidenceæ¨¡å¼æ‰ç®—weighted_score
            weighted_score = self.calculate_weighted_score(preds, labels)
            results['weighted_score'] = weighted_score
        
        return results
    
    def print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ç»“æœï¼ˆä»… Top-10 åˆæ³•ç‡ï¼‰"""
        if self.batch_legal_at10:
            avg_legal_at10 = sum(self.batch_legal_at10) / len(self.batch_legal_at10)
            print(f"[SID_STATS] Top-10 åˆæ³•ç‡: {avg_legal_at10:.3f}")