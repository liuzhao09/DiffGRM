/root/anaconda3/envs/lz_grm_pd/lib/python3.10/site-packages/accelerate/accelerator.py:399: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:root:Device: cuda
INFO:root:[DATASET] Amazon Reviews 2014 for category: CDs_and_Vinyl
INFO:root:[DATASET] Reviews have been processed...
INFO:root:[DATASET] Metadata has been processed...
INFO:root:[Dataset] AmazonReviews2014
	Number of users: 75259
	Number of items: 64444
	Number of interactions: 1097592
	Average item sequence length: 14.584195910123706
INFO:root:[TOKENIZER] Index factory: OPQ4,IVF1,PQ4x8
INFO:root:[TOKENIZER] Loading PCA-ed sentence embeddings from cache/AmazonReviews2014/CDs_and_Vinyl/processed/bge-large-en-v1.5_pca256.sent_emb...
INFO:root:[TOKENIZER] Sentence embeddings shape: (64443, 256)
INFO:root:[TOKENIZER] Force regenerating OPQ quantization results...
INFO:root:[TOKENIZER] Items for training: 64181 of 64443
INFO:root:[TOKENIZER] Training items sample: ['B0000024SB', 'B000000X7U', 'B000089CKC', 'B006WVC22K', 'B00006J3WI', 'B001B0G5KC', 'B000000HRQ', 'B00000K1KM', 'B0000DG057', 'B0000025BF']
INFO:root:[TOKENIZER] Mask shape: (64443,), True count: 64181
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss:Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
INFO:root:[TOKENIZER] sent_embs shape: (64443, 256)
INFO:root:[TOKENIZER] train_mask shape: (64443,)
INFO:root:[TOKENIZER] train_mask True count: 64181
INFO:root:[TOKENIZER] Training index...
INFO:root:[TOKENIZER] Saving semantic IDs to cache/AmazonReviews2014/CDs_and_Vinyl/processed/bge-large-en-v1.5_pca256_OPQ4,IVF1,PQ4x8.sem_ids...
INFO:root:[TOKENIZER] Loading semantic IDs from cache/AmazonReviews2014/CDs_and_Vinyl/processed/bge-large-en-v1.5_pca256_OPQ4,IVF1,PQ4x8.sem_ids...
INFO:root:[TOKENIZER] Force regenerate OPQ enabled, ignoring existing mapping files
INFO:root:[TOKENIZER] Force regenerate OPQ enabled, generating new mappings
INFO:root:[TOKENIZER] Saved mappings with tag: bge-large-en-v1.5_pca256_OPQ4,IVF1,PQ4x8_4d to cache/AmazonReviews2014/CDs_and_Vinyl/processed
INFO:root:[TOKENIZER] Files: item_id2tokens_bge-large-en-v1.5_pca256_OPQ4,IVF1,PQ4x8_4d.npy, tokens2item_bge-large-en-v1.5_pca256_OPQ4,IVF1,PQ4x8_4d.pkl
Tokenizing train set:   0%|          | 0/585354 [00:00<?, ? examples/s]Tokenizing train set:   0%|          | 393/585354 [00:00<05:58, 1631.23 examples/s]Tokenizing train set:   0%|          | 1792/585354 [00:00<01:43, 5629.59 examples/s]Tokenizing train set:   0%|          | 2804/585354 [00:00<01:22, 7085.64 examples/s]Tokenizing train set:   1%|          | 3874/585354 [00:00<01:54, 5092.46 examples/s]Tokenizing train set:   1%|          | 4903/585354 [00:00<01:33, 6228.42 examples/s]Tokenizing train set:   1%|          | 5834/585354 [00:01<01:59, 4829.47 examples/s]Tokenizing train set:   1%|          | 6795/585354 [00:01<01:41, 5718.48 examples/s]Tokenizing train set:   1%|▏         | 7854/585354 [00:01<01:25, 6758.20 examples/s]Tokenizing train set:   2%|▏         | 9000/585354 [00:01<01:52, 5106.02 examples/s]Tokenizing train set:   2%|▏         | 10007/585354 [00:01<01:36, 5990.44 examples/s]Tokenizing train set:   2%|▏         | 11000/585354 [00:01<01:25, 6716.15 examples/s]Tokenizing train set:   2%|▏         | 12000/585354 [00:02<02:00, 4752.33 examples/s]Tokenizing train set:   2%|▏         | 13014/585354 [00:02<01:41, 5661.79 examples/s]Tokenizing train set:   2%|▏         | 14016/585354 [00:02<01:56, 4900.13 examples/s]Tokenizing train set:   3%|▎         | 15000/585354 [00:02<01:39, 5738.09 examples/s]Tokenizing train set:   3%|▎         | 16022/585354 [00:02<01:25, 6622.86 examples/s]Tokenizing train set:   3%|▎         | 17000/585354 [00:03<01:48, 5215.11 examples/s]Tokenizing train set:   3%|▎         | 18000/585354 [00:03<01:33, 6058.45 examples/s]Tokenizing train set:   3%|▎         | 19017/585354 [00:03<01:21, 6906.88 examples/s]Tokenizing train set:   3%|▎         | 20000/585354 [00:03<01:44, 5399.35 examples/s]Tokenizing train set:   4%|▎         | 21020/585354 [00:03<01:29, 6302.63 examples/s]Tokenizing train set:   4%|▍         | 22016/585354 [00:04<01:57, 4784.13 examples/s]Tokenizing train set:   4%|▍         | 23000/585354 [00:04<01:40, 5611.13 examples/s]Tokenizing train set:   4%|▍         | 24020/585354 [00:04<01:26, 6502.16 examples/s]Tokenizing train set:   4%|▍         | 25000/585354 [00:04<01:54, 4910.01 examples/s]Tokenizing train set:   4%|▍         | 26007/585354 [00:04<01:36, 5809.34 examples/s]Tokenizing train set:   5%|▍         | 27027/585354 [00:04<01:23, 6678.71 examples/s]Tokenizing train set:   5%|▍         | 28000/585354 [00:05<01:51, 4988.83 examples/s]Tokenizing train set:   5%|▍         | 29016/585354 [00:05<01:34, 5901.68 examples/s]Tokenizing train set:   5%|▌         | 30016/585354 [00:05<01:54, 4855.41 examples/s]Tokenizing train set:   5%|▌         | 31000/585354 [00:05<01:37, 5688.49 examples/s]Tokenizing train set:   5%|▌         | 32039/585354 [00:05<01:23, 6611.85 examples/s]Tokenizing train set:   6%|▌         | 33000/585354 [00:05<01:51, 4959.26 examples/s]Tokenizing train set:   6%|▌         | 34016/585354 [00:06<01:33, 5874.48 examples/s]Tokenizing train set:   6%|▌         | 35033/585354 [00:06<01:21, 6736.67 examples/s]Tokenizing train set:   6%|▌         | 36000/585354 [00:06<01:50, 4963.17 examples/s]Tokenizing train set:   6%|▋         | 37000/585354 [00:06<01:34, 5813.53 examples/s]Tokenizing train set:   6%|▋         | 38016/585354 [00:06<01:54, 4779.83 examples/s]Tokenizing train set:   7%|▋         | 39000/585354 [00:06<01:37, 5597.81 examples/s]Tokenizing train set:   7%|▋         | 40000/585354 [00:07<01:24, 6442.78 examples/s]Tokenizing train set:   7%|▋         | 41000/585354 [00:07<01:50, 4933.48 examples/s]Tokenizing train set:   7%|▋         | 42000/585354 [00:07<01:33, 5816.52 examples/s]Tokenizing train set:   7%|▋         | 43000/585354 [00:07<01:21, 6640.52 examples/s]Tokenizing train set:   8%|▊         | 44000/585354 [00:07<01:47, 5049.19 examples/s]Tokenizing train set:   8%|▊         | 45032/585354 [00:07<01:30, 5986.22 examples/s]Tokenizing train set:   8%|▊         | 46016/585354 [00:08<01:51, 4828.41 examples/s]Tokenizing train set:   8%|▊         | 47000/585354 [00:08<01:34, 5667.96 examples/s]Tokenizing train set:   8%|▊         | 48034/585354 [00:08<01:21, 6583.73 examples/s]Tokenizing train set:   8%|▊         | 49000/585354 [00:08<01:47, 5006.04 examples/s]Tokenizing train set:   9%|▊         | 50023/585354 [00:08<01:30, 5932.21 examples/s]Tokenizing train set:   9%|▊         | 51080/585354 [00:08<01:17, 6868.13 examples/s]Tokenizing train set:   9%|▉         | 52000/585354 [00:09<01:44, 5109.10 examples/s]Tokenizing train set:   9%|▉         | 53028/585354 [00:09<01:28, 6044.83 examples/s]Tokenizing train set:   9%|▉         | 54016/585354 [00:09<01:48, 4900.25 examples/s]Tokenizing train set:   9%|▉         | 55000/585354 [00:09<01:32, 5739.71 examples/s]Tokenizing train set:  10%|▉         | 56042/585354 [00:09<01:19, 6667.34 examples/s]Tokenizing train set:  10%|▉         | 57000/585354 [00:10<01:45, 5017.46 examples/s]Tokenizing train set:  10%|▉         | 58012/585354 [00:10<01:29, 5924.88 examples/s]Tokenizing train set:  10%|█         | 59031/585354 [00:10<01:17, 6789.08 examples/s]Tokenizing train set:  10%|█         | 60000/585354 [00:10<01:42, 5119.60 examples/s]Tokenizing train set:  10%|█         | 61002/585354 [00:10<01:27, 6005.18 examples/s]Tokenizing train set:  11%|█         | 62016/585354 [00:11<01:47, 4859.87 examples/s]Tokenizing train set:  11%|█         | 63000/585354 [00:11<01:31, 5686.66 examples/s]Tokenizing train set:  11%|█         | 64046/585354 [00:11<01:18, 6623.86 examples/s]Tokenizing train set:  11%|█         | 65000/585354 [00:11<01:43, 5014.79 examples/s]Tokenizing train set:  11%|█▏        | 66038/585354 [00:11<01:27, 5967.79 examples/s]Tokenizing train set:  11%|█▏        | 67069/585354 [00:11<01:15, 6845.67 examples/s]Tokenizing train set:  12%|█▏        | 68000/585354 [00:12<01:39, 5178.92 examples/s]Tokenizing train set:  12%|█▏        | 69064/585354 [00:12<01:23, 6178.79 examples/s]Tokenizing train set:  12%|█▏        | 70016/585354 [00:12<01:44, 4947.92 examples/s]Tokenizing train set:  12%|█▏        | 71000/585354 [00:12<01:28, 5792.19 examples/s]Tokenizing train set:  12%|█▏        | 72000/585354 [00:12<01:20, 6410.88 examples/s]Tokenizing train set:  12%|█▏        | 73000/585354 [00:13<01:44, 4924.25 examples/s]Tokenizing train set:  13%|█▎        | 74060/585354 [00:13<01:26, 5916.78 examples/s]Tokenizing train set:  13%|█▎        | 75069/585354 [00:13<01:15, 6750.76 examples/s]Tokenizing train set:  13%|█▎        | 75989/585354 [00:13<01:34, 5372.96 examples/s]Tokenizing train set:  13%|█▎        | 76980/585354 [00:13<01:21, 6231.17 examples/s]Tokenizing train set:  13%|█▎        | 78000/585354 [00:13<01:16, 6591.93 examples/s]Tokenizing train set:  13%|█▎        | 78778/585354 [00:13<01:37, 5201.11 examples/s]Tokenizing train set:  14%|█▎        | 79810/585354 [00:14<01:21, 6182.46 examples/s]Tokenizing train set:  14%|█▍        | 80570/585354 [00:14<01:48, 4635.35 examples/s]Tokenizing train set:  14%|█▍        | 81807/585354 [00:14<01:26, 5840.85 examples/s]Tokenizing train set:  14%|█▍        | 82846/585354 [00:14<01:14, 6749.89 examples/s]Tokenizing train set:  14%|█▍        | 84000/585354 [00:14<01:38, 5086.24 examples/s]Tokenizing train set:  15%|█▍        | 85083/585354 [00:15<01:22, 6069.03 examples/s]Tokenizing train set:  15%|█▍        | 86016/585354 [00:15<01:39, 5023.21 examples/s]Tokenizing train set:  15%|█▍        | 87000/585354 [00:15<01:25, 5843.98 examples/s]Tokenizing train set:  15%|█▌        | 88065/585354 [00:15<01:13, 6796.62 examples/s]Tokenizing train set:  15%|█▌        | 89000/585354 [00:15<01:37, 5113.93 examples/s]Tokenizing train set:  15%|█▌        | 90067/585354 [00:15<01:21, 6112.28 examples/s]Tokenizing train set:  16%|█▌        | 91116/585354 [00:15<01:10, 7005.01 examples/s]Tokenizing train set:  16%|█▌        | 92000/585354 [00:16<01:35, 5161.15 examples/s]Tokenizing train set:  16%|█▌        | 93048/585354 [00:16<01:20, 6135.55 examples/s]Tokenizing train set:  16%|█▌        | 94016/585354 [00:16<01:39, 4931.16 examples/s]Tokenizing train set:  16%|█▌        | 95000/585354 [00:16<01:25, 5767.58 examples/s]Tokenizing train set:  16%|█▋        | 96061/585354 [00:16<01:12, 6733.59 examples/s]Tokenizing train set:  17%|█▋        | 97000/585354 [00:17<01:36, 5057.90 examples/s]Tokenizing train set:  17%|█▋        | 98034/585354 [00:17<01:21, 6006.12 examples/s]Tokenizing train set:  17%|█▋        | 99065/585354 [00:17<01:10, 6884.35 examples/s]Tokenizing train set:  17%|█▋        | 100000/585354 [00:17<01:34, 5113.30 examples/s]Tokenizing train set:  17%|█▋        | 101042/585354 [00:17<01:19, 6075.05 examples/s]Tokenizing train set:  17%|█▋        | 102016/585354 [00:18<01:37, 4933.50 examples/s]Tokenizing train set:  18%|█▊        | 103000/585354 [00:18<01:23, 5769.65 examples/s]Tokenizing train set:  18%|█▊        | 104041/585354 [00:18<01:11, 6695.18 examples/s]Tokenizing train set:  18%|█▊        | 105000/585354 [00:18<01:34, 5068.18 examples/s]Tokenizing train set:  18%|█▊        | 106020/585354 [00:18<01:20, 5989.15 examples/s]Tokenizing train set:  18%|█▊        | 107041/585354 [00:18<01:09, 6849.76 examples/s]Tokenizing train set:  18%|█▊        | 108000/585354 [00:19<01:32, 5176.47 examples/s]Tokenizing train set:  19%|█▊        | 109031/585354 [00:19<01:17, 6112.98 examples/s]Tokenizing train set:  19%|█▉        | 110016/585354 [00:19<01:36, 4946.74 examples/s]Tokenizing train set:  19%|█▉        | 111000/585354 [00:19<01:22, 5774.55 examples/s]Tokenizing train set:  19%|█▉        | 112005/585354 [00:19<01:11, 6626.54 examples/s]Tokenizing train set:  19%|█▉        | 113000/585354 [00:19<01:33, 5037.68 examples/s]Tokenizing train set:  19%|█▉        | 114001/585354 [00:20<01:19, 5922.82 examples/s]Tokenizing train set:  20%|█▉        | 115007/585354 [00:20<01:09, 6761.51 examples/s]Tokenizing train set:  20%|█▉        | 116000/585354 [00:20<01:31, 5146.69 examples/s]Tokenizing train set:  20%|█▉        | 117027/585354 [00:20<01:17, 6072.61 examples/s]Tokenizing train set:  20%|██        | 118016/585354 [00:20<01:35, 4919.27 examples/s]Tokenizing train set:  20%|██        | 119000/585354 [00:20<01:21, 5746.84 examples/s]Tokenizing train set:  21%|██        | 120030/585354 [00:21<01:09, 6648.55 examples/s]Tokenizing train set:  21%|██        | 121000/585354 [00:21<01:31, 5087.46 examples/s]Tokenizing train set:  21%|██        | 122042/585354 [00:21<01:16, 6044.65 examples/s]Tokenizing train set:  21%|██        | 123067/585354 [00:21<01:06, 6902.62 examples/s]Tokenizing train set:  21%|██        | 124000/585354 [00:21<01:29, 5147.25 examples/s]Tokenizing train set:  21%|██▏       | 125053/585354 [00:21<01:15, 6128.12 examples/s]Tokenizing train set:  22%|██▏       | 126016/585354 [00:22<01:34, 4867.40 examples/s]Tokenizing train set:  22%|██▏       | 127000/585354 [00:22<01:20, 5712.97 examples/s]Tokenizing train set:  22%|██▏       | 128004/585354 [00:22<01:09, 6569.32 examples/s]Tokenizing train set:  22%|██▏       | 129000/585354 [00:22<01:32, 4949.71 examples/s]Tokenizing train set:  22%|██▏       | 130000/585354 [00:22<01:18, 5827.72 examples/s]Tokenizing train set:  22%|██▏       | 131032/585354 [00:22<01:07, 6721.85 examples/s]Tokenizing train set:  23%|██▎       | 132000/585354 [00:23<01:30, 5021.93 examples/s]Tokenizing train set:  23%|██▎       | 133012/585354 [00:23<01:16, 5927.43 examples/s]Tokenizing train set:  23%|██▎       | 134016/585354 [00:23<01:34, 4794.32 examples/s]Tokenizing train set:  23%|██▎       | 135000/585354 [00:23<01:20, 5628.33 examples/s]Tokenizing train set:  23%|██▎       | 136056/585354 [00:23<01:08, 6588.63 examples/s]Tokenizing train set:  23%|██▎       | 137000/585354 [00:24<01:29, 5028.08 examples/s]Tokenizing train set:  24%|██▎       | 138021/585354 [00:24<01:15, 5951.18 examples/s]Tokenizing train set:  24%|██▍       | 139067/585354 [00:24<01:05, 6865.22 examples/s]Tokenizing train set:  24%|██▍       | 140000/585354 [00:24<01:26, 5133.00 examples/s]Tokenizing train set:  24%|██▍       | 141032/585354 [00:24<01:13, 6075.08 examples/s]Tokenizing train set:  24%|██▍       | 141993/585354 [00:25<01:27, 5053.15 examples/s]Tokenizing train set:  24%|██▍       | 142919/585354 [00:25<01:16, 5807.36 examples/s]Tokenizing train set:  25%|██▍       | 143961/585354 [00:25<01:05, 6747.93 examples/s]Tokenizing train set:  25%|██▍       | 145000/585354 [00:25<01:35, 4600.49 examples/s]Tokenizing train set:  25%|██▍       | 146073/585354 [00:25<01:18, 5604.22 examples/s]Tokenizing train set:  25%|██▌       | 147108/585354 [00:25<01:07, 6503.82 examples/s]Tokenizing train set:  25%|██▌       | 148000/585354 [00:26<01:29, 4892.84 examples/s]Tokenizing train set:  25%|██▌       | 149021/585354 [00:26<01:14, 5823.00 examples/s]Tokenizing train set:  26%|██▌       | 150051/585354 [00:26<01:04, 6717.89 examples/s]Tokenizing train set:  26%|██▌       | 151103/585354 [00:26<01:23, 5187.30 examples/s]Tokenizing train set:  26%|██▌       | 152124/585354 [00:26<01:11, 6084.96 examples/s]Tokenizing train set:  26%|██▌       | 153000/585354 [00:27<01:32, 4678.86 examples/s]Tokenizing train set:  26%|██▋       | 154032/585354 [00:27<01:16, 5638.74 examples/s]Tokenizing train set:  26%|██▋       | 155060/585354 [00:27<01:05, 6546.17 examples/s]Tokenizing train set:  27%|██▋       | 156000/585354 [00:27<01:26, 4978.17 examples/s]Tokenizing train set:  27%|██▋       | 157049/585354 [00:27<01:11, 5959.16 examples/s]Tokenizing train set:  27%|██▋       | 158087/585354 [00:27<01:02, 6854.53 examples/s]Tokenizing train set:  27%|██▋       | 159127/585354 [00:28<01:21, 5260.11 examples/s]Tokenizing train set:  27%|██▋       | 160167/585354 [00:28<01:08, 6188.17 examples/s]Tokenizing train set:  28%|██▊       | 161000/585354 [00:28<01:29, 4717.20 examples/s]Tokenizing train set:  28%|██▊       | 162043/585354 [00:28<01:14, 5702.91 examples/s]Tokenizing train set:  28%|██▊       | 163112/585354 [00:28<01:03, 6688.81 examples/s]Tokenizing train set:  28%|██▊       | 164000/585354 [00:28<01:24, 5012.91 examples/s]Tokenizing train set:  28%|██▊       | 165057/585354 [00:29<01:09, 6014.55 examples/s]Tokenizing train set:  28%|██▊       | 166077/585354 [00:29<01:01, 6869.98 examples/s]Tokenizing train set:  29%|██▊       | 167133/585354 [00:29<01:19, 5290.33 examples/s]Tokenizing train set:  29%|██▊       | 168172/585354 [00:29<01:07, 6215.93 examples/s]Tokenizing train set:  29%|██▉       | 169000/585354 [00:29<01:28, 4719.09 examples/s]Tokenizing train set:  29%|██▉       | 170040/585354 [00:29<01:12, 5700.74 examples/s]Tokenizing train set:  29%|██▉       | 171081/585354 [00:30<01:02, 6631.70 examples/s]Tokenizing train set:  29%|██▉       | 172000/585354 [00:30<01:22, 4995.32 examples/s]Tokenizing train set:  30%|██▉       | 173056/585354 [00:30<01:08, 5993.19 examples/s]Tokenizing train set:  30%|██▉       | 174086/585354 [00:30<00:59, 6870.92 examples/s]Tokenizing train set:  30%|██▉       | 175118/585354 [00:30<01:17, 5264.97 examples/s]Tokenizing train set:  30%|███       | 176173/585354 [00:30<01:05, 6223.70 examples/s]Tokenizing train set:  30%|███       | 177000/585354 [00:31<01:25, 4767.17 examples/s]Tokenizing train set:  30%|███       | 178032/585354 [00:31<01:11, 5734.50 examples/s]Tokenizing train set:  31%|███       | 179090/585354 [00:31<01:00, 6699.86 examples/s]Tokenizing train set:  31%|███       | 180000/585354 [00:31<01:20, 5030.99 examples/s]Tokenizing train set:  31%|███       | 181042/585354 [00:31<01:07, 6002.54 examples/s]Tokenizing train set:  31%|███       | 182060/585354 [00:31<00:58, 6858.11 examples/s]Tokenizing train set:  31%|███       | 182922/585354 [00:32<01:14, 5394.34 examples/s]Tokenizing train set:  31%|███▏      | 183941/585354 [00:32<01:03, 6322.59 examples/s]Tokenizing train set:  32%|███▏      | 185000/585354 [00:32<01:25, 4672.71 examples/s]Tokenizing train set:  32%|███▏      | 186063/585354 [00:32<01:10, 5663.77 examples/s]Tokenizing train set:  32%|███▏      | 187089/585354 [00:32<01:00, 6545.97 examples/s]Tokenizing train set:  32%|███▏      | 188000/585354 [00:33<01:20, 4954.63 examples/s]Tokenizing train set:  32%|███▏      | 189063/585354 [00:33<01:06, 5956.98 examples/s]Tokenizing train set:  32%|███▏      | 190112/585354 [00:33<00:57, 6870.24 examples/s]Tokenizing train set:  33%|███▎      | 191136/585354 [00:33<01:14, 5266.11 examples/s]Tokenizing train set:  33%|███▎      | 192211/585354 [00:33<01:02, 6256.80 examples/s]Tokenizing train set:  33%|███▎      | 193834/585354 [00:34<01:11, 5507.58 examples/s]Tokenizing train set:  33%|███▎      | 194920/585354 [00:34<01:01, 6377.99 examples/s]Tokenizing train set:  33%|███▎      | 196000/585354 [00:34<01:18, 4940.47 examples/s]Tokenizing train set:  34%|███▎      | 197069/585354 [00:34<01:06, 5836.01 examples/s]Tokenizing train set:  34%|███▍      | 198149/585354 [00:34<00:57, 6739.43 examples/s]Tokenizing train set:  34%|███▍      | 199148/585354 [00:35<01:12, 5291.96 examples/s]Tokenizing train set:  34%|███▍      | 200242/585354 [00:35<01:01, 6273.26 examples/s]Tokenizing train set:  34%|███▍      | 201834/585354 [00:35<01:09, 5555.78 examples/s]Tokenizing train set:  35%|███▍      | 202885/585354 [00:35<01:00, 6355.65 examples/s]Tokenizing train set:  35%|███▍      | 204000/585354 [00:35<01:16, 4963.35 examples/s]Tokenizing train set:  35%|███▌      | 205042/585354 [00:36<01:05, 5807.30 examples/s]Tokenizing train set:  35%|███▌      | 206082/585354 [00:36<00:57, 6638.17 examples/s]Tokenizing train set:  35%|███▌      | 206953/585354 [00:36<01:10, 5379.65 examples/s]Tokenizing train set:  36%|███▌      | 207847/585354 [00:36<01:02, 6029.62 examples/s]Tokenizing train set:  36%|███▌      | 208729/585354 [00:36<01:20, 4678.37 examples/s]Tokenizing train set:  36%|███▌      | 209834/585354 [00:36<01:05, 5692.87 examples/s]Tokenizing train set:  36%|███▌      | 210909/585354 [00:36<00:56, 6682.63 examples/s]Tokenizing train set:  36%|███▌      | 212000/585354 [00:37<01:15, 4960.38 examples/s]Tokenizing train set:  36%|███▋      | 213092/585354 [00:37<01:02, 5968.29 examples/s]Tokenizing train set:  37%|███▋      | 214155/585354 [00:37<00:53, 6874.30 examples/s]Tokenizing train set:  37%|███▋      | 215141/585354 [00:37<01:10, 5261.08 examples/s]Tokenizing train set:  37%|███▋      | 216222/585354 [00:37<00:59, 6250.67 examples/s]Tokenizing train set:  37%|███▋      | 217824/585354 [00:38<01:06, 5499.54 examples/s]Tokenizing train set:  37%|███▋      | 218872/585354 [00:38<00:58, 6307.97 examples/s]Tokenizing train set:  38%|███▊      | 220000/585354 [00:38<01:13, 4955.70 examples/s]Tokenizing train set:  38%|███▊      | 221092/585354 [00:38<01:01, 5882.21 examples/s]Tokenizing train set:  38%|███▊      | 222174/585354 [00:39<01:12, 5003.88 examples/s]Tokenizing train set:  38%|███▊      | 223140/585354 [00:39<01:02, 5751.33 examples/s]Tokenizing train set:  38%|███▊      | 224214/585354 [00:39<00:54, 6682.05 examples/s]Tokenizing train set:  39%|███▊      | 225825/585354 [00:39<01:02, 5714.74 examples/s]Tokenizing train set:  39%|███▉      | 226859/585354 [00:39<00:55, 6479.77 examples/s]Tokenizing train set:  39%|███▉      | 228000/585354 [00:40<01:11, 4989.42 examples/s]Tokenizing train set:  39%|███▉      | 229037/585354 [00:40<01:01, 5823.74 examples/s]Tokenizing train set:  39%|███▉      | 230073/585354 [00:40<00:53, 6639.14 examples/s]Tokenizing train set:  39%|███▉      | 231114/585354 [00:40<01:10, 5026.40 examples/s]Tokenizing train set:  40%|███▉      | 232134/585354 [00:40<01:00, 5884.83 examples/s]Tokenizing train set:  40%|███▉      | 233000/585354 [00:41<01:16, 4630.91 examples/s]Tokenizing train set:  40%|███▉      | 234076/585354 [00:41<01:02, 5636.87 examples/s]Tokenizing train set:  40%|████      | 235125/585354 [00:41<00:53, 6561.30 examples/s]Tokenizing train set:  40%|████      | 236000/585354 [00:41<01:10, 4968.06 examples/s]Tokenizing train set:  40%|████      | 237066/585354 [00:41<00:58, 5978.55 examples/s]Tokenizing train set:  41%|████      | 238140/585354 [00:41<00:50, 6941.12 examples/s]Tokenizing train set:  41%|████      | 239125/585354 [00:42<01:05, 5296.27 examples/s]Tokenizing train set:  41%|████      | 240180/585354 [00:42<00:55, 6255.66 examples/s]Tokenizing train set:  41%|████      | 241000/585354 [00:42<01:12, 4744.96 examples/s]Tokenizing train set:  41%|████▏     | 242064/585354 [00:42<00:59, 5770.78 examples/s]Tokenizing train set:  42%|████▏     | 243122/585354 [00:42<00:50, 6726.89 examples/s]Tokenizing train set:  42%|████▏     | 244000/585354 [00:42<01:07, 5020.05 examples/s]Tokenizing train set:  42%|████▏     | 245085/585354 [00:43<00:56, 6074.58 examples/s]Tokenizing train set:  42%|████▏     | 246161/585354 [00:43<00:48, 7036.28 examples/s]Tokenizing train set:  42%|████▏     | 247131/585354 [00:43<01:03, 5301.03 examples/s]Tokenizing train set:  42%|████▏     | 248238/585354 [00:43<00:53, 6359.34 examples/s]Tokenizing train set:  43%|████▎     | 249857/585354 [00:43<01:00, 5585.66 examples/s]Tokenizing train set:  43%|████▎     | 250951/585354 [00:43<00:51, 6467.42 examples/s]Tokenizing train set:  43%|████▎     | 252000/585354 [00:44<01:07, 4905.89 examples/s]Tokenizing train set:  43%|████▎     | 253112/585354 [00:44<00:56, 5874.23 examples/s]Tokenizing train set:  43%|████▎     | 254174/585354 [00:44<01:06, 4977.79 examples/s]Tokenizing train set:  44%|████▎     | 255150/585354 [00:44<00:57, 5748.26 examples/s]Tokenizing train set:  44%|████▍     | 256249/585354 [00:44<00:48, 6728.68 examples/s]Tokenizing train set:  44%|████▍     | 257821/585354 [00:45<00:57, 5693.88 examples/s]Tokenizing train set:  44%|████▍     | 258861/585354 [00:45<00:50, 6474.44 examples/s]Tokenizing train set:  44%|████▍     | 260000/585354 [00:45<01:04, 5029.50 examples/s]Tokenizing train set:  45%|████▍     | 261109/585354 [00:45<00:54, 5978.17 examples/s]Tokenizing train set:  45%|████▍     | 262174/585354 [00:46<01:03, 5054.23 examples/s]Tokenizing train set:  45%|████▍     | 263122/585354 [00:46<00:55, 5770.03 examples/s]Tokenizing train set:  45%|████▌     | 264223/585354 [00:46<00:47, 6753.91 examples/s]Tokenizing train set:  45%|████▌     | 265837/585354 [00:46<00:55, 5763.94 examples/s]Tokenizing train set:  46%|████▌     | 266916/585354 [00:46<00:48, 6598.59 examples/s]Tokenizing train set:  46%|████▌     | 268000/585354 [00:47<01:02, 5041.64 examples/s]Tokenizing train set:  46%|████▌     | 269121/585354 [00:47<00:52, 6010.30 examples/s]Tokenizing train set:  46%|████▌     | 270174/585354 [00:47<01:01, 5122.97 examples/s]Tokenizing train set:  46%|████▋     | 271161/585354 [00:47<00:53, 5900.28 examples/s]Tokenizing train set:  47%|████▋     | 272729/585354 [00:47<00:58, 5381.55 examples/s]Tokenizing train set:  47%|████▋     | 273845/585354 [00:47<00:50, 6197.03 examples/s]Tokenizing train set:  47%|████▋     | 274940/585354 [00:48<00:43, 7061.14 examples/s]Tokenizing train set:  47%|████▋     | 276000/585354 [00:48<00:59, 5190.96 examples/s]Tokenizing train set:  47%|████▋     | 277067/585354 [00:48<00:50, 6090.17 examples/s]Tokenizing train set:  48%|████▊     | 278153/585354 [00:48<00:43, 6994.78 examples/s]Tokenizing train set:  48%|████▊     | 279154/585354 [00:48<00:56, 5462.61 examples/s]Tokenizing train set:  48%|████▊     | 280729/585354 [00:49<00:59, 5145.16 examples/s]Tokenizing train set:  48%|████▊     | 281821/585354 [00:49<00:51, 5949.33 examples/s]Tokenizing train set:  48%|████▊     | 282870/585354 [00:49<00:44, 6752.51 examples/s]Tokenizing train set:  49%|████▊     | 284000/585354 [00:49<00:58, 5185.39 examples/s]Tokenizing train set:  49%|████▊     | 285091/585354 [00:49<00:49, 6118.83 examples/s]Tokenizing train set:  49%|████▉     | 286156/585354 [00:50<00:42, 6974.88 examples/s]Tokenizing train set:  49%|████▉     | 287781/585354 [00:50<00:54, 5452.95 examples/s]Tokenizing train set:  49%|████▉     | 288729/585354 [00:50<01:03, 4653.76 examples/s]Tokenizing train set:  50%|████▉     | 289848/585354 [00:50<00:53, 5544.19 examples/s]Tokenizing train set:  50%|████▉     | 290917/585354 [00:50<00:45, 6422.41 examples/s]Tokenizing train set:  50%|████▉     | 292000/585354 [00:51<01:02, 4727.75 examples/s]Tokenizing train set:  50%|█████     | 293077/585354 [00:51<00:51, 5656.46 examples/s]Tokenizing train set:  50%|█████     | 294171/585354 [00:51<00:44, 6607.46 examples/s]Tokenizing train set:  50%|█████     | 295151/585354 [00:51<00:55, 5195.91 examples/s]Tokenizing train set:  51%|█████     | 296214/585354 [00:51<00:47, 6135.55 examples/s]Tokenizing train set:  51%|█████     | 297834/585354 [00:52<00:52, 5478.57 examples/s]Tokenizing train set:  51%|█████     | 298937/585354 [00:52<00:44, 6367.25 examples/s]Tokenizing train set:  51%|█████▏    | 300000/585354 [00:52<00:57, 4950.29 examples/s]Tokenizing train set:  51%|█████▏    | 301112/585354 [00:52<00:48, 5908.23 examples/s]Tokenizing train set:  52%|█████▏    | 302174/585354 [00:53<00:56, 4989.86 examples/s]Tokenizing train set:  52%|█████▏    | 303182/585354 [00:53<00:48, 5807.10 examples/s]Tokenizing train set:  52%|█████▏    | 304729/585354 [00:53<00:52, 5338.56 examples/s]Tokenizing train set:  52%|█████▏    | 305834/585354 [00:53<00:45, 6176.48 examples/s]Tokenizing train set:  52%|█████▏    | 306921/585354 [00:53<00:39, 7031.11 examples/s]Tokenizing train set:  53%|█████▎    | 308000/585354 [00:54<00:52, 5236.30 examples/s]Tokenizing train set:  53%|█████▎    | 309090/585354 [00:54<00:44, 6171.36 examples/s]Tokenizing train set:  53%|█████▎    | 310174/585354 [00:54<00:52, 5216.66 examples/s]Tokenizing train set:  53%|█████▎    | 311150/585354 [00:54<00:45, 5978.10 examples/s]Tokenizing train set:  53%|█████▎    | 312729/585354 [00:54<00:49, 5475.92 examples/s]Tokenizing train set:  54%|█████▎    | 313876/585354 [00:54<00:42, 6351.82 examples/s]Tokenizing train set:  54%|█████▍    | 314970/585354 [00:55<00:37, 7199.63 examples/s]Tokenizing train set:  54%|█████▍    | 316000/585354 [00:55<00:51, 5267.94 examples/s]Tokenizing train set:  54%|█████▍    | 317094/585354 [00:55<00:43, 6214.60 examples/s]Tokenizing train set:  54%|█████▍    | 318174/585354 [00:55<00:51, 5181.78 examples/s]Tokenizing train set:  55%|█████▍    | 319180/585354 [00:55<00:44, 5997.48 examples/s]Tokenizing train set:  55%|█████▍    | 320729/585354 [00:56<00:48, 5420.87 examples/s]Tokenizing train set:  55%|█████▍    | 321855/585354 [00:56<00:41, 6287.23 examples/s]Tokenizing train set:  55%|█████▌    | 322953/585354 [00:56<00:36, 7147.52 examples/s]Tokenizing train set:  55%|█████▌    | 324000/585354 [00:56<00:49, 5240.76 examples/s]Tokenizing train set:  56%|█████▌    | 325147/585354 [00:56<00:41, 6274.51 examples/s]Tokenizing train set:  56%|█████▌    | 326174/585354 [00:57<00:50, 5145.47 examples/s]Tokenizing train set:  56%|█████▌    | 327148/585354 [00:57<00:43, 5911.03 examples/s]Tokenizing train set:  56%|█████▌    | 328240/585354 [00:57<00:37, 6872.34 examples/s]Tokenizing train set:  56%|█████▋    | 329819/585354 [00:57<00:44, 5770.77 examples/s]Tokenizing train set:  57%|█████▋    | 330939/585354 [00:57<00:38, 6682.78 examples/s]Tokenizing train set:  57%|█████▋    | 332000/585354 [00:58<00:49, 5101.79 examples/s]Tokenizing train set:  57%|█████▋    | 333133/585354 [00:58<00:41, 6091.56 examples/s]Tokenizing train set:  57%|█████▋    | 334174/585354 [00:58<00:49, 5085.40 examples/s]Tokenizing train set:  57%|█████▋    | 335175/585354 [00:58<00:42, 5887.91 examples/s]Tokenizing train set:  58%|█████▊    | 336729/585354 [00:58<00:46, 5370.05 examples/s]Tokenizing train set:  58%|█████▊    | 337881/585354 [00:59<00:39, 6274.53 examples/s]Tokenizing train set:  58%|█████▊    | 338984/585354 [00:59<00:34, 7143.02 examples/s]Tokenizing train set:  58%|█████▊    | 340000/585354 [00:59<00:46, 5239.60 examples/s]Tokenizing train set:  58%|█████▊    | 341144/585354 [00:59<00:38, 6270.45 examples/s]Tokenizing train set:  58%|█████▊    | 342174/585354 [00:59<00:47, 5155.20 examples/s]Tokenizing train set:  59%|█████▊    | 343191/585354 [00:59<00:40, 5993.47 examples/s]Tokenizing train set:  59%|█████▉    | 344729/585354 [01:00<00:44, 5416.37 examples/s]Tokenizing train set:  59%|█████▉    | 345866/585354 [01:00<00:38, 6285.82 examples/s]Tokenizing train set:  59%|█████▉    | 346977/585354 [01:00<00:33, 7174.57 examples/s]Tokenizing train set:  59%|█████▉    | 348000/585354 [01:00<00:45, 5239.15 examples/s]Tokenizing train set:  60%|█████▉    | 349000/585354 [01:00<00:39, 5985.58 examples/s]Tokenizing train set:  60%|█████▉    | 350116/585354 [01:01<00:33, 6967.83 examples/s]Tokenizing train set:  60%|█████▉    | 351184/585354 [01:01<00:44, 5294.58 examples/s]Tokenizing train set:  60%|██████    | 352729/585354 [01:01<00:46, 5000.09 examples/s]Tokenizing train set:  60%|██████    | 353849/585354 [01:01<00:39, 5858.61 examples/s]Tokenizing train set:  61%|██████    | 354953/585354 [01:01<00:34, 6756.74 examples/s]Tokenizing train set:  61%|██████    | 356000/585354 [01:02<00:45, 4996.64 examples/s]Tokenizing train set:  61%|██████    | 357151/585354 [01:02<00:37, 6033.31 examples/s]Tokenizing train set:  61%|██████    | 358174/585354 [01:02<00:45, 4967.40 examples/s]Tokenizing train set:  61%|██████▏   | 359205/585354 [01:02<00:38, 5831.27 examples/s]Tokenizing train set:  62%|██████▏   | 360729/585354 [01:03<00:42, 5263.51 examples/s]Tokenizing train set:  62%|██████▏   | 361910/585354 [01:03<00:35, 6217.97 examples/s]Tokenizing train set:  62%|██████▏   | 363000/585354 [01:03<00:33, 6652.08 examples/s]Tokenizing train set:  62%|██████▏   | 364000/585354 [01:03<00:41, 5326.61 examples/s]Tokenizing train set:  62%|██████▏   | 365135/585354 [01:03<00:34, 6347.19 examples/s]Tokenizing train set:  63%|██████▎   | 366174/585354 [01:04<00:42, 5200.87 examples/s]Tokenizing train set:  63%|██████▎   | 368000/585354 [01:04<00:33, 6531.74 examples/s]Tokenizing train set:  63%|██████▎   | 369000/585354 [01:04<00:41, 5252.46 examples/s]Tokenizing train set:  63%|██████▎   | 370108/585354 [01:04<00:34, 6158.68 examples/s]Tokenizing train set:  63%|██████▎   | 371238/585354 [01:04<00:30, 7093.38 examples/s]Tokenizing train set:  64%|██████▎   | 372897/585354 [01:05<00:35, 6040.15 examples/s]Tokenizing train set:  64%|██████▍   | 374000/585354 [01:05<00:32, 6519.74 examples/s]Tokenizing train set:  64%|██████▍   | 374982/585354 [01:05<00:37, 5615.92 examples/s]Tokenizing train set:  64%|██████▍   | 376000/585354 [01:05<00:34, 6069.77 examples/s]Tokenizing train set:  64%|██████▍   | 376729/585354 [01:05<00:42, 4920.09 examples/s]Tokenizing train set:  65%|██████▍   | 377873/585354 [01:05<00:34, 5960.63 examples/s]Tokenizing train set:  65%|██████▍   | 378960/585354 [01:06<00:29, 6921.87 examples/s]Tokenizing train set:  65%|██████▍   | 380000/585354 [01:06<00:40, 5084.87 examples/s]Tokenizing train set:  65%|██████▌   | 381176/585354 [01:06<00:32, 6228.50 examples/s]Tokenizing train set:  65%|██████▌   | 382174/585354 [01:06<00:40, 5065.99 examples/s]Tokenizing train set:  65%|██████▌   | 383226/585354 [01:06<00:33, 5990.88 examples/s]Tokenizing train set:  66%|██████▌   | 384729/585354 [01:07<00:37, 5414.78 examples/s]Tokenizing train set:  66%|██████▌   | 385892/585354 [01:07<00:31, 6342.28 examples/s]Tokenizing train set:  66%|██████▌   | 387000/585354 [01:07<00:29, 6796.90 examples/s]Tokenizing train set:  66%|██████▋   | 388000/585354 [01:07<00:36, 5443.96 examples/s]Tokenizing train set:  66%|██████▋   | 389164/585354 [01:07<00:30, 6517.29 examples/s]Tokenizing train set:  67%|██████▋   | 390174/585354 [01:08<00:36, 5323.01 examples/s]Tokenizing train set:  67%|██████▋   | 391215/585354 [01:08<00:31, 6200.72 examples/s]Tokenizing train set:  67%|██████▋   | 392729/585354 [01:08<00:34, 5547.02 examples/s]Tokenizing train set:  67%|██████▋   | 393889/585354 [01:08<00:29, 6440.62 examples/s]Tokenizing train set:  67%|██████▋   | 395000/585354 [01:08<00:27, 6881.89 examples/s]Tokenizing train set:  68%|██████▊   | 396000/585354 [01:09<00:34, 5410.37 examples/s]Tokenizing train set:  68%|██████▊   | 397191/585354 [01:09<00:28, 6525.92 examples/s]Tokenizing train set:  68%|██████▊   | 398174/585354 [01:09<00:35, 5284.16 examples/s]Tokenizing train set:  68%|██████▊   | 399214/585354 [01:09<00:30, 6161.18 examples/s]Tokenizing train set:  68%|██████▊   | 400729/585354 [01:09<00:33, 5521.90 examples/s]Tokenizing train set:  69%|██████▊   | 401914/585354 [01:09<00:28, 6469.86 examples/s]Tokenizing train set:  69%|██████▉   | 403000/585354 [01:10<00:26, 6879.38 examples/s]Tokenizing train set:  69%|██████▉   | 404000/585354 [01:10<00:33, 5449.30 examples/s]Tokenizing train set:  69%|██████▉   | 405149/585354 [01:10<00:27, 6493.27 examples/s]Tokenizing train set:  69%|██████▉   | 406174/585354 [01:10<00:33, 5302.42 examples/s]Tokenizing train set:  70%|██████▉   | 407242/585354 [01:10<00:28, 6225.36 examples/s]Tokenizing train set:  70%|██████▉   | 408729/585354 [01:11<00:31, 5605.21 examples/s]Tokenizing train set:  70%|███████   | 409914/585354 [01:11<00:26, 6558.94 examples/s]Tokenizing train set:  70%|███████   | 411000/585354 [01:11<00:25, 6945.00 examples/s]Tokenizing train set:  70%|███████   | 412000/585354 [01:11<00:31, 5430.88 examples/s]Tokenizing train set:  71%|███████   | 413175/585354 [01:11<00:26, 6520.61 examples/s]Tokenizing train set:  71%|███████   | 414174/585354 [01:12<00:32, 5285.67 examples/s]Tokenizing train set:  71%|███████   | 415225/585354 [01:12<00:27, 6182.00 examples/s]Tokenizing train set:  71%|███████   | 416729/585354 [01:12<00:30, 5559.06 examples/s]Tokenizing train set:  71%|███████▏  | 417917/585354 [01:12<00:25, 6515.05 examples/s]Tokenizing train set:  72%|███████▏  | 419000/585354 [01:12<00:23, 6943.64 examples/s]Tokenizing train set:  72%|███████▏  | 420000/585354 [01:13<00:30, 5481.72 examples/s]Tokenizing train set:  72%|███████▏  | 421137/585354 [01:13<00:25, 6504.85 examples/s]Tokenizing train set:  72%|███████▏  | 422174/585354 [01:13<00:30, 5415.11 examples/s]Tokenizing train set:  72%|███████▏  | 423229/585354 [01:13<00:25, 6310.72 examples/s]Tokenizing train set:  73%|███████▎  | 424729/585354 [01:13<00:28, 5668.54 examples/s]Tokenizing train set:  73%|███████▎  | 425894/585354 [01:13<00:24, 6589.89 examples/s]Tokenizing train set:  73%|███████▎  | 427000/585354 [01:14<00:22, 6986.09 examples/s]Tokenizing train set:  73%|███████▎  | 428000/585354 [01:14<00:28, 5436.32 examples/s]Tokenizing train set:  73%|███████▎  | 429164/585354 [01:14<00:24, 6505.52 examples/s]Tokenizing train set:  73%|███████▎  | 430174/585354 [01:14<00:28, 5369.01 examples/s]Tokenizing train set:  74%|███████▎  | 431201/585354 [01:14<00:24, 6218.83 examples/s]Tokenizing train set:  74%|███████▍  | 432729/585354 [01:15<00:27, 5566.76 examples/s]Tokenizing train set:  74%|███████▍  | 433866/585354 [01:15<00:23, 6457.31 examples/s]Tokenizing train set:  74%|███████▍  | 435000/585354 [01:15<00:21, 6932.39 examples/s]Tokenizing train set:  74%|███████▍  | 436000/585354 [01:15<00:27, 5491.87 examples/s]Tokenizing train set:  75%|███████▍  | 437135/585354 [01:15<00:22, 6507.85 examples/s]Tokenizing train set:  75%|███████▍  | 438174/585354 [01:16<00:27, 5356.96 examples/s]Tokenizing train set:  75%|███████▌  | 439227/585354 [01:16<00:23, 6250.48 examples/s]Tokenizing train set:  75%|███████▌  | 440729/585354 [01:16<00:25, 5581.52 examples/s]Tokenizing train set:  75%|███████▌  | 441919/585354 [01:16<00:21, 6533.78 examples/s]Tokenizing train set:  76%|███████▌  | 443000/585354 [01:16<00:20, 6948.41 examples/s]Tokenizing train set:  76%|███████▌  | 444000/585354 [01:16<00:25, 5450.58 examples/s]Tokenizing train set:  76%|███████▌  | 445178/585354 [01:17<00:21, 6544.67 examples/s]Tokenizing train set:  76%|███████▌  | 446174/585354 [01:17<00:25, 5370.65 examples/s]Tokenizing train set:  76%|███████▋  | 447238/585354 [01:17<00:21, 6286.49 examples/s]Tokenizing train set:  77%|███████▋  | 448729/585354 [01:17<00:24, 5560.51 examples/s]Tokenizing train set:  77%|███████▋  | 449903/585354 [01:17<00:20, 6490.95 examples/s]Tokenizing train set:  77%|███████▋  | 451000/585354 [01:18<00:19, 6930.35 examples/s]Tokenizing train set:  77%|███████▋  | 452000/585354 [01:18<00:24, 5490.90 examples/s]Tokenizing train set:  77%|███████▋  | 453164/585354 [01:18<00:20, 6560.76 examples/s]Tokenizing train set:  78%|███████▊  | 454174/585354 [01:18<00:24, 5335.69 examples/s]Tokenizing train set:  78%|███████▊  | 455225/585354 [01:18<00:20, 6229.06 examples/s]Tokenizing train set:  78%|███████▊  | 456729/585354 [01:19<00:23, 5581.97 examples/s]Tokenizing train set:  78%|███████▊  | 457892/585354 [01:19<00:19, 6508.51 examples/s]Tokenizing train set:  78%|███████▊  | 459000/585354 [01:19<00:18, 6954.98 examples/s]Tokenizing train set:  79%|███████▊  | 460000/585354 [01:19<00:22, 5496.54 examples/s]Tokenizing train set:  79%|███████▉  | 461201/585354 [01:19<00:18, 6624.23 examples/s]Tokenizing train set:  79%|███████▉  | 462174/585354 [01:20<00:23, 5322.73 examples/s]Tokenizing train set:  79%|███████▉  | 463249/585354 [01:20<00:19, 6260.17 examples/s]Tokenizing train set:  79%|███████▉  | 464729/585354 [01:20<00:21, 5530.81 examples/s]Tokenizing train set:  80%|███████▉  | 465914/585354 [01:20<00:18, 6476.38 examples/s]Tokenizing train set:  80%|███████▉  | 467000/585354 [01:20<00:17, 6886.12 examples/s]Tokenizing train set:  80%|███████▉  | 468000/585354 [01:20<00:21, 5492.73 examples/s]Tokenizing train set:  80%|████████  | 469171/585354 [01:21<00:17, 6575.82 examples/s]Tokenizing train set:  80%|████████  | 470174/585354 [01:21<00:21, 5337.86 examples/s]Tokenizing train set:  81%|████████  | 471893/585354 [01:21<00:16, 6947.73 examples/s]Tokenizing train set:  81%|████████  | 473000/585354 [01:21<00:21, 5321.27 examples/s]Tokenizing train set:  81%|████████  | 474148/585354 [01:21<00:17, 6284.55 examples/s]Tokenizing train set:  81%|████████  | 475452/585354 [01:22<00:20, 5470.85 examples/s]Tokenizing train set:  81%|████████▏ | 476915/585354 [01:22<00:16, 6709.29 examples/s]Tokenizing train set:  82%|████████▏ | 478000/585354 [01:22<00:15, 7073.99 examples/s]Tokenizing train set:  82%|████████▏ | 478978/585354 [01:22<00:18, 5832.73 examples/s]Tokenizing train set:  82%|████████▏ | 480000/585354 [01:22<00:16, 6291.79 examples/s]Tokenizing train set:  82%|████████▏ | 481000/585354 [01:23<00:20, 5099.47 examples/s]Tokenizing train set:  82%|████████▏ | 482192/585354 [01:23<00:16, 6244.33 examples/s]Tokenizing train set:  83%|████████▎ | 483452/585354 [01:23<00:18, 5430.05 examples/s]Tokenizing train set:  83%|████████▎ | 484921/585354 [01:23<00:14, 6733.79 examples/s]Tokenizing train set:  83%|████████▎ | 486000/585354 [01:23<00:14, 7079.35 examples/s]Tokenizing train set:  83%|████████▎ | 486997/585354 [01:24<00:16, 5955.46 examples/s]Tokenizing train set:  83%|████████▎ | 488000/585354 [01:24<00:15, 6370.53 examples/s]Tokenizing train set:  84%|████████▎ | 489000/585354 [01:24<00:18, 5148.62 examples/s]Tokenizing train set:  84%|████████▎ | 490187/585354 [01:24<00:15, 6298.05 examples/s]Tokenizing train set:  84%|████████▍ | 491452/585354 [01:24<00:17, 5463.02 examples/s]Tokenizing train set:  84%|████████▍ | 492916/585354 [01:24<00:13, 6768.78 examples/s]Tokenizing train set:  84%|████████▍ | 494000/585354 [01:25<00:12, 7105.78 examples/s]Tokenizing train set:  85%|████████▍ | 495000/585354 [01:25<00:16, 5563.31 examples/s]Tokenizing train set:  85%|████████▍ | 496133/585354 [01:25<00:13, 6561.86 examples/s]Tokenizing train set:  85%|████████▍ | 497000/585354 [01:25<00:17, 5061.07 examples/s]Tokenizing train set:  85%|████████▌ | 498168/585354 [01:25<00:14, 6188.94 examples/s]Tokenizing train set:  85%|████████▌ | 499452/585354 [01:26<00:16, 5368.39 examples/s]Tokenizing train set:  86%|████████▌ | 500919/585354 [01:26<00:12, 6673.80 examples/s]Tokenizing train set:  86%|████████▌ | 502000/585354 [01:26<00:11, 7018.29 examples/s]Tokenizing train set:  86%|████████▌ | 503000/585354 [01:26<00:14, 5594.73 examples/s]Tokenizing train set:  86%|████████▌ | 504135/585354 [01:26<00:12, 6596.45 examples/s]Tokenizing train set:  86%|████████▋ | 505000/585354 [01:27<00:15, 5132.02 examples/s]Tokenizing train set:  86%|████████▋ | 506161/585354 [01:27<00:12, 6247.04 examples/s]Tokenizing train set:  87%|████████▋ | 507452/585354 [01:27<00:14, 5416.79 examples/s]Tokenizing train set:  87%|████████▋ | 508919/585354 [01:27<00:11, 6729.97 examples/s]Tokenizing train set:  87%|████████▋ | 510000/585354 [01:27<00:10, 7101.23 examples/s]Tokenizing train set:  87%|████████▋ | 511000/585354 [01:28<00:13, 5559.09 examples/s]Tokenizing train set:  88%|████████▊ | 512195/585354 [01:28<00:10, 6666.20 examples/s]Tokenizing train set:  88%|████████▊ | 513914/585354 [01:28<00:12, 5937.06 examples/s]Tokenizing train set:  88%|████████▊ | 515000/585354 [01:28<00:11, 6392.82 examples/s]Tokenizing train set:  88%|████████▊ | 516000/585354 [01:28<00:13, 5223.98 examples/s]Tokenizing train set:  88%|████████▊ | 517188/585354 [01:29<00:10, 6287.08 examples/s]Tokenizing train set:  89%|████████▊ | 518174/585354 [01:29<00:12, 5206.47 examples/s]Tokenizing train set:  89%|████████▉ | 519896/585354 [01:29<00:09, 6785.85 examples/s]Tokenizing train set:  89%|████████▉ | 521000/585354 [01:29<00:12, 5316.79 examples/s]Tokenizing train set:  89%|████████▉ | 522161/585354 [01:29<00:10, 6285.44 examples/s]Tokenizing train set:  89%|████████▉ | 523452/585354 [01:30<00:11, 5548.01 examples/s]Tokenizing train set:  90%|████████▉ | 524908/585354 [01:30<00:08, 6760.27 examples/s]Tokenizing train set:  90%|████████▉ | 526000/585354 [01:30<00:08, 7114.31 examples/s]Tokenizing train set:  90%|█████████ | 526997/585354 [01:30<00:09, 5946.69 examples/s]Tokenizing train set:  90%|█████████ | 528000/585354 [01:30<00:09, 6366.05 examples/s]Tokenizing train set:  90%|█████████ | 529000/585354 [01:31<00:11, 5090.02 examples/s]Tokenizing train set:  91%|█████████ | 530172/585354 [01:31<00:08, 6200.95 examples/s]Tokenizing train set:  91%|█████████ | 531452/585354 [01:31<00:09, 5450.36 examples/s]Tokenizing train set:  91%|█████████ | 532922/585354 [01:31<00:07, 6756.37 examples/s]Tokenizing train set:  91%|█████████ | 534000/585354 [01:31<00:07, 7102.59 examples/s]Tokenizing train set:  91%|█████████▏| 535000/585354 [01:32<00:09, 5584.39 examples/s]Tokenizing train set:  92%|█████████▏| 536196/585354 [01:32<00:07, 6688.41 examples/s]Tokenizing train set:  92%|█████████▏| 537888/585354 [01:32<00:08, 5909.73 examples/s]Tokenizing train set:  92%|█████████▏| 539000/585354 [01:32<00:07, 6413.94 examples/s]Tokenizing train set:  92%|█████████▏| 540000/585354 [01:32<00:08, 5228.37 examples/s]Tokenizing train set:  92%|█████████▏| 541226/585354 [01:32<00:06, 6350.63 examples/s]Tokenizing train set:  93%|█████████▎| 542174/585354 [01:33<00:08, 5284.96 examples/s]Tokenizing train set:  93%|█████████▎| 543918/585354 [01:33<00:05, 6910.11 examples/s]Tokenizing train set:  93%|█████████▎| 545000/585354 [01:33<00:07, 5322.30 examples/s]Tokenizing train set:  93%|█████████▎| 546162/585354 [01:33<00:06, 6300.48 examples/s]Tokenizing train set:  94%|█████████▎| 547452/585354 [01:34<00:06, 5571.00 examples/s]Tokenizing train set:  94%|█████████▍| 548928/585354 [01:34<00:05, 6825.97 examples/s]Tokenizing train set:  94%|█████████▍| 550000/585354 [01:34<00:04, 7164.65 examples/s]Tokenizing train set:  94%|█████████▍| 551000/585354 [01:34<00:06, 5717.82 examples/s]Tokenizing train set:  94%|█████████▍| 552202/585354 [01:34<00:04, 6811.35 examples/s]Tokenizing train set:  95%|█████████▍| 553938/585354 [01:35<00:05, 6068.61 examples/s]Tokenizing train set:  95%|█████████▍| 555000/585354 [01:35<00:04, 6503.02 examples/s]Tokenizing train set:  95%|█████████▍| 556000/585354 [01:35<00:05, 5305.21 examples/s]Tokenizing train set:  95%|█████████▌| 557201/585354 [01:35<00:04, 6382.96 examples/s]Tokenizing train set:  95%|█████████▌| 558174/585354 [01:35<00:05, 5305.34 examples/s]Tokenizing train set:  96%|█████████▌| 559934/585354 [01:35<00:03, 6954.33 examples/s]Tokenizing train set:  96%|█████████▌| 561000/585354 [01:36<00:04, 5323.53 examples/s]Tokenizing train set:  96%|█████████▌| 562198/585354 [01:36<00:03, 6357.38 examples/s]Tokenizing train set:  96%|█████████▋| 563452/585354 [01:36<00:03, 5505.67 examples/s]Tokenizing train set:  97%|█████████▋| 564927/585354 [01:36<00:03, 6755.58 examples/s]Tokenizing train set:  97%|█████████▋| 566000/585354 [01:36<00:02, 7105.45 examples/s]Tokenizing train set:  97%|█████████▋| 567000/585354 [01:37<00:03, 5619.08 examples/s]Tokenizing train set:  97%|█████████▋| 568230/585354 [01:37<00:02, 6762.42 examples/s]Tokenizing train set:  97%|█████████▋| 569908/585354 [01:37<00:02, 6032.66 examples/s]Tokenizing train set:  98%|█████████▊| 571000/585354 [01:37<00:02, 6482.66 examples/s]Tokenizing train set:  98%|█████████▊| 572000/585354 [01:38<00:02, 5329.94 examples/s]Tokenizing train set:  98%|█████████▊| 573000/585354 [01:38<00:02, 5136.11 examples/s]Tokenizing train set:  98%|█████████▊| 574161/585354 [01:38<00:01, 6191.56 examples/s]Tokenizing train set:  98%|█████████▊| 575000/585354 [01:38<00:02, 4932.01 examples/s]Tokenizing train set:  98%|█████████▊| 576183/585354 [01:38<00:01, 6085.22 examples/s]Tokenizing train set:  99%|█████████▊| 577000/585354 [01:39<00:01, 4748.29 examples/s]Tokenizing train set:  99%|█████████▉| 578181/585354 [01:39<00:01, 5934.72 examples/s]Tokenizing train set:  99%|█████████▉| 579452/585354 [01:39<00:01, 5194.03 examples/s]Tokenizing train set:  99%|█████████▉| 580933/585354 [01:39<00:00, 6555.08 examples/s]Tokenizing train set:  99%|█████████▉| 582000/585354 [01:39<00:00, 6960.82 examples/s]Tokenizing train set: 100%|█████████▉| 583000/585354 [01:40<00:00, 5503.70 examples/s]Tokenizing train set: 100%|█████████▉| 584232/585354 [01:40<00:00, 6682.96 examples/s]Tokenizing train set: 100%|██████████| 585354/585354 [01:40<00:00, 5301.26 examples/s]Tokenizing train set: 100%|██████████| 585354/585354 [01:40<00:00, 5827.39 examples/s]
Tokenizing val set:   0%|          | 0/75258 [00:00<?, ? examples/s]Tokenizing val set:   1%|▏         | 1000/75258 [00:00<00:09, 7810.53 examples/s]Tokenizing val set:   3%|▎         | 2000/75258 [00:00<00:09, 8097.03 examples/s]Tokenizing val set:   4%|▍         | 3000/75258 [00:00<00:15, 4642.33 examples/s]Tokenizing val set:   5%|▌         | 4000/75258 [00:00<00:12, 5741.58 examples/s]Tokenizing val set:   7%|▋         | 5000/75258 [00:00<00:10, 6594.48 examples/s]Tokenizing val set:   8%|▊         | 6000/75258 [00:01<00:14, 4887.77 examples/s]Tokenizing val set:   9%|▉         | 7000/75258 [00:01<00:12, 5678.66 examples/s]Tokenizing val set:  10%|█         | 7900/75258 [00:01<00:14, 4624.62 examples/s]Tokenizing val set:  12%|█▏        | 8705/75258 [00:01<00:12, 5179.98 examples/s]Tokenizing val set:  13%|█▎        | 9701/75258 [00:01<00:10, 6056.10 examples/s]Tokenizing val set:  14%|█▍        | 10624/75258 [00:01<00:09, 6552.56 examples/s]Tokenizing val set:  16%|█▌        | 11718/75258 [00:02<00:12, 4929.74 examples/s]Tokenizing val set:  17%|█▋        | 12762/75258 [00:02<00:10, 5866.63 examples/s]Tokenizing val set:  18%|█▊        | 13689/75258 [00:02<00:13, 4693.85 examples/s]Tokenizing val set:  20%|█▉        | 14741/75258 [00:02<00:10, 5540.82 examples/s]Tokenizing val set:  21%|██        | 15772/75258 [00:02<00:09, 6414.33 examples/s]Tokenizing val set:  23%|██▎       | 17000/75258 [00:03<00:11, 4973.11 examples/s]Tokenizing val set:  24%|██▍       | 18039/75258 [00:03<00:09, 5870.14 examples/s]Tokenizing val set:  25%|██▌       | 18966/75258 [00:03<00:11, 4860.66 examples/s]Tokenizing val set:  26%|██▋       | 19758/75258 [00:03<00:10, 5331.56 examples/s]Tokenizing val set:  28%|██▊       | 20769/75258 [00:03<00:08, 6235.35 examples/s]Tokenizing val set:  29%|██▉       | 21811/75258 [00:03<00:07, 7136.99 examples/s]Tokenizing val set:  30%|███       | 22814/75258 [00:04<00:10, 5199.45 examples/s]Tokenizing val set:  32%|███▏      | 23852/75258 [00:04<00:08, 6146.31 examples/s]Tokenizing val set:  33%|███▎      | 25000/75258 [00:04<00:10, 4810.51 examples/s]Tokenizing val set:  35%|███▍      | 26071/75258 [00:04<00:08, 5778.52 examples/s]Tokenizing val set:  36%|███▌      | 27136/75258 [00:04<00:07, 6702.33 examples/s]Tokenizing val set:  38%|███▊      | 28856/75258 [00:05<00:07, 6014.74 examples/s]Tokenizing val set:  40%|███▉      | 29874/75258 [00:05<00:08, 5080.18 examples/s]Tokenizing val set:  41%|████      | 30845/75258 [00:05<00:07, 5781.28 examples/s]Tokenizing val set:  42%|████▏     | 31970/75258 [00:05<00:06, 6769.84 examples/s]Tokenizing val set:  44%|████▍     | 33000/75258 [00:05<00:08, 5065.15 examples/s]Tokenizing val set:  45%|████▌     | 34112/75258 [00:06<00:06, 6066.70 examples/s]Tokenizing val set:  47%|████▋     | 35234/75258 [00:06<00:05, 7051.22 examples/s]Tokenizing val set:  49%|████▉     | 36876/75258 [00:06<00:06, 6084.13 examples/s]Tokenizing val set:  50%|█████     | 37839/75258 [00:06<00:05, 6661.33 examples/s]Tokenizing val set:  52%|█████▏    | 38865/75258 [00:06<00:06, 5253.99 examples/s]Tokenizing val set:  53%|█████▎    | 40000/75258 [00:07<00:05, 5925.86 examples/s]Tokenizing val set:  54%|█████▍    | 40782/75258 [00:07<00:06, 5040.96 examples/s]Tokenizing val set:  56%|█████▌    | 41867/75258 [00:07<00:05, 5955.04 examples/s]Tokenizing val set:  57%|█████▋    | 43000/75258 [00:07<00:04, 6573.22 examples/s]Tokenizing val set:  58%|█████▊    | 44000/75258 [00:07<00:05, 5228.42 examples/s]Tokenizing val set:  60%|█████▉    | 45142/75258 [00:07<00:04, 6316.88 examples/s]Tokenizing val set:  62%|██████▏   | 46399/75258 [00:08<00:05, 5383.29 examples/s]Tokenizing val set:  64%|██████▎   | 47890/75258 [00:08<00:04, 6699.28 examples/s]Tokenizing val set:  65%|██████▌   | 48953/75258 [00:08<00:04, 5436.69 examples/s]Tokenizing val set:  66%|██████▋   | 49900/75258 [00:08<00:04, 6098.36 examples/s]Tokenizing val set:  68%|██████▊   | 51000/75258 [00:08<00:03, 6610.85 examples/s]Tokenizing val set:  69%|██████▉   | 51848/75258 [00:09<00:04, 5403.89 examples/s]Tokenizing val set:  70%|███████   | 52895/75258 [00:09<00:03, 6288.75 examples/s]Tokenizing val set:  72%|███████▏  | 54000/75258 [00:09<00:03, 6801.04 examples/s]Tokenizing val set:  73%|███████▎  | 55000/75258 [00:09<00:03, 5227.19 examples/s]Tokenizing val set:  75%|███████▍  | 56148/75258 [00:09<00:03, 6335.45 examples/s]Tokenizing val set:  77%|███████▋  | 57623/75258 [00:10<00:03, 5593.75 examples/s]Tokenizing val set:  78%|███████▊  | 58887/75258 [00:10<00:02, 6602.08 examples/s]Tokenizing val set:  80%|███████▉  | 60000/75258 [00:10<00:02, 7024.87 examples/s]Tokenizing val set:  81%|████████  | 61000/75258 [00:10<00:02, 5431.31 examples/s]Tokenizing val set:  84%|████████▎ | 62956/75258 [00:10<00:01, 7228.50 examples/s]Tokenizing val set:  85%|████████▌ | 64000/75258 [00:11<00:02, 5085.55 examples/s]Tokenizing val set:  87%|████████▋ | 65160/75258 [00:11<00:01, 6034.68 examples/s]Tokenizing val set:  88%|████████▊ | 66000/75258 [00:11<00:01, 5016.56 examples/s]Tokenizing val set:  89%|████████▉ | 67172/75258 [00:11<00:01, 6094.99 examples/s]Tokenizing val set:  91%|█████████▏| 68676/75258 [00:11<00:01, 5706.80 examples/s]Tokenizing val set:  93%|█████████▎| 69927/75258 [00:11<00:00, 6689.90 examples/s]Tokenizing val set:  94%|█████████▍| 71000/75258 [00:12<00:00, 7069.17 examples/s]Tokenizing val set:  96%|█████████▌| 72000/75258 [00:12<00:00, 5774.84 examples/s]Tokenizing val set:  97%|█████████▋| 73000/75258 [00:12<00:00, 6458.79 examples/s]Tokenizing val set:  98%|█████████▊| 73953/75258 [00:12<00:00, 5594.70 examples/s]Tokenizing val set: 100%|█████████▉| 74987/75258 [00:12<00:00, 6474.17 examples/s]Tokenizing val set: 100%|██████████| 75258/75258 [00:12<00:00, 5847.61 examples/s]
Tokenizing test set:   0%|          | 0/75258 [00:00<?, ? examples/s]Tokenizing test set:   1%|▏         | 1000/75258 [00:00<00:09, 7808.35 examples/s]Tokenizing test set:   3%|▎         | 1884/75258 [00:00<00:15, 4593.08 examples/s]Tokenizing test set:   3%|▎         | 2610/75258 [00:00<00:13, 5373.01 examples/s]Tokenizing test set:   5%|▍         | 3677/75258 [00:00<00:10, 6670.58 examples/s]Tokenizing test set:   6%|▌         | 4635/75258 [00:00<00:14, 4829.73 examples/s]Tokenizing test set:   8%|▊         | 5754/75258 [00:00<00:11, 6033.73 examples/s]Tokenizing test set:   9%|▉         | 6650/75258 [00:01<00:10, 6677.52 examples/s]Tokenizing test set:  10%|█         | 7644/75258 [00:01<00:13, 5013.92 examples/s]Tokenizing test set:  12%|█▏        | 8724/75258 [00:01<00:11, 5957.52 examples/s]Tokenizing test set:  13%|█▎        | 9676/75258 [00:01<00:13, 4923.38 examples/s]Tokenizing test set:  14%|█▍        | 10677/75258 [00:01<00:11, 5647.92 examples/s]Tokenizing test set:  16%|█▌        | 11732/75258 [00:02<00:09, 6517.63 examples/s]Tokenizing test set:  17%|█▋        | 13000/75258 [00:02<00:11, 5242.53 examples/s]Tokenizing test set:  19%|█▊        | 14014/75258 [00:02<00:10, 6085.87 examples/s]Tokenizing test set:  20%|█▉        | 14953/75258 [00:02<00:11, 5308.44 examples/s]Tokenizing test set:  21%|██        | 15808/75258 [00:02<00:10, 5897.12 examples/s]Tokenizing test set:  22%|██▏       | 16848/75258 [00:02<00:08, 6824.17 examples/s]Tokenizing test set:  24%|██▎       | 17848/75258 [00:03<00:10, 5475.89 examples/s]Tokenizing test set:  25%|██▍       | 18794/75258 [00:03<00:09, 6212.05 examples/s]Tokenizing test set:  26%|██▋       | 19783/75258 [00:03<00:07, 6959.26 examples/s]Tokenizing test set:  28%|██▊       | 20742/75258 [00:03<00:09, 5454.62 examples/s]Tokenizing test set:  29%|██▉       | 21795/75258 [00:03<00:08, 6320.14 examples/s]Tokenizing test set:  30%|███       | 22870/75258 [00:03<00:07, 7264.21 examples/s]Tokenizing test set:  32%|███▏      | 24000/75258 [00:04<00:09, 5447.38 examples/s]Tokenizing test set:  33%|███▎      | 25000/75258 [00:04<00:08, 6256.38 examples/s]Tokenizing test set:  35%|███▍      | 26081/75258 [00:04<00:06, 7189.87 examples/s]Tokenizing test set:  36%|███▌      | 27000/75258 [00:04<00:08, 5460.59 examples/s]Tokenizing test set:  37%|███▋      | 28079/75258 [00:04<00:07, 6461.18 examples/s]Tokenizing test set:  39%|███▉      | 29180/75258 [00:04<00:06, 7422.74 examples/s]Tokenizing test set:  41%|████      | 30831/75258 [00:05<00:06, 6499.61 examples/s]Tokenizing test set:  42%|████▏     | 31782/75258 [00:05<00:08, 5427.00 examples/s]Tokenizing test set:  44%|████▎     | 32842/75258 [00:05<00:06, 6249.69 examples/s]Tokenizing test set:  45%|████▌     | 33971/75258 [00:05<00:05, 7220.59 examples/s]Tokenizing test set:  47%|████▋     | 35000/75258 [00:05<00:07, 5474.47 examples/s]Tokenizing test set:  48%|████▊     | 36115/75258 [00:05<00:06, 6474.79 examples/s]Tokenizing test set:  49%|████▉     | 37101/75258 [00:06<00:05, 7155.37 examples/s]Tokenizing test set:  50%|█████     | 38000/75258 [00:06<00:06, 5547.45 examples/s]Tokenizing test set:  52%|█████▏    | 39111/75258 [00:06<00:05, 6601.28 examples/s]Tokenizing test set:  53%|█████▎    | 39953/75258 [00:06<00:06, 5557.03 examples/s]Tokenizing test set:  54%|█████▍    | 40913/75258 [00:06<00:05, 6344.17 examples/s]Tokenizing test set:  56%|█████▌    | 42000/75258 [00:06<00:04, 6847.16 examples/s]Tokenizing test set:  57%|█████▋    | 42848/75258 [00:07<00:05, 5650.92 examples/s]Tokenizing test set:  58%|█████▊    | 43851/75258 [00:07<00:04, 6497.75 examples/s]Tokenizing test set:  60%|█████▉    | 44957/75258 [00:07<00:04, 7511.11 examples/s]Tokenizing test set:  61%|██████    | 46000/75258 [00:07<00:05, 5458.30 examples/s]Tokenizing test set:  63%|██████▎   | 47134/75258 [00:07<00:04, 6553.15 examples/s]Tokenizing test set:  65%|██████▍   | 48623/75258 [00:08<00:04, 5944.98 examples/s]Tokenizing test set:  66%|██████▋   | 49887/75258 [00:08<00:03, 6956.78 examples/s]Tokenizing test set:  68%|██████▊   | 51000/75258 [00:08<00:03, 7299.17 examples/s]Tokenizing test set:  69%|██████▉   | 52000/75258 [00:08<00:04, 5778.41 examples/s]Tokenizing test set:  71%|███████   | 53131/75258 [00:08<00:03, 6774.51 examples/s]Tokenizing test set:  72%|███████▏  | 54227/75258 [00:08<00:03, 5734.73 examples/s]Tokenizing test set:  74%|███████▍  | 55881/75258 [00:09<00:02, 7229.18 examples/s]Tokenizing test set:  75%|███████▌  | 56782/75258 [00:09<00:03, 5798.29 examples/s]Tokenizing test set:  77%|███████▋  | 57887/75258 [00:09<00:02, 6676.19 examples/s]Tokenizing test set:  78%|███████▊  | 59000/75258 [00:09<00:02, 7103.85 examples/s]Tokenizing test set:  80%|███████▉  | 60000/75258 [00:09<00:02, 5663.95 examples/s]Tokenizing test set:  81%|████████  | 61132/75258 [00:09<00:02, 6688.34 examples/s]Tokenizing test set:  83%|████████▎ | 62399/75258 [00:10<00:02, 5846.15 examples/s]Tokenizing test set:  85%|████████▍ | 63892/75258 [00:10<00:01, 7139.96 examples/s]Tokenizing test set:  86%|████████▋ | 64953/75258 [00:10<00:01, 5841.52 examples/s]Tokenizing test set:  88%|████████▊ | 65907/75258 [00:10<00:01, 6480.28 examples/s]Tokenizing test set:  89%|████████▉ | 67000/75258 [00:10<00:01, 6951.72 examples/s]Tokenizing test set:  90%|█████████ | 67848/75258 [00:11<00:01, 5799.39 examples/s]Tokenizing test set:  92%|█████████▏| 68888/75258 [00:11<00:00, 6661.81 examples/s]Tokenizing test set:  93%|█████████▎| 70000/75258 [00:11<00:00, 7133.15 examples/s]Tokenizing test set:  94%|█████████▍| 71000/75258 [00:11<00:00, 5648.12 examples/s]Tokenizing test set:  96%|█████████▌| 72174/75258 [00:11<00:00, 6796.62 examples/s]Tokenizing test set:  98%|█████████▊| 73623/75258 [00:11<00:00, 5894.95 examples/s]Tokenizing test set: 100%|█████████▉| 74901/75258 [00:12<00:00, 6931.04 examples/s]Tokenizing test set: 100%|██████████| 75258/75258 [00:12<00:00, 6208.93 examples/s]
INFO:root:DIFF_GRM(
  (embedding): Embedding(1027, 256)
  (item_mlp): Sequential(
    (0): Linear(in_features=1024, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
  )
  (mask_emb_table): Embedding(4, 256)
  (pos_emb_enc): Embedding(50, 256)
  (encoder_blocks): ModuleList(
    (0-1): 2 x EncoderBlock(
      (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (attn): MultiHeadAttention(
        (qkv): Linear(in_features=256, out_features=768, bias=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (mlp): FeedForward(
        (c_fc): Linear(in_features=256, out_features=1024, bias=True)
        (c_proj): Linear(in_features=1024, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (decoder_blocks): ModuleList(
    (0-3): 4 x DecoderBlock(
      (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (self_attn): MultiHeadAttention(
        (qkv): Linear(in_features=256, out_features=768, bias=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (cross_attn): MultiHeadAttention(
        (qkv): Linear(in_features=256, out_features=768, bias=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (mlp): FeedForward(
        (c_fc): Linear(in_features=256, out_features=1024, bias=True)
        (c_proj): Linear(in_features=1024, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (output_adapter): Identity()
  (drop): Dropout(p=0.1, inplace=False)
)
INFO:root:6,391,040
[MODEL] ▶ use SEQUENTIAL views: steps=4, paths=8, augment_factor=32
[DIFF_GRM] Using shared embedding dot-product output layer
[TRAINING] Evaluation config: start from epoch 20, interval: 2
Training - [Epoch 1]:   0%|          | 0/572 [00:00<?, ?it/s]Training - [Epoch 1]:   0%|          | 0/572 [00:21<?, ?it/s]
[DIFF_GRM] Using RPG_ED-style encoder: MLP compression + fixed 50-length sequence
[DIFF_GRM] vocab_size: 1027, codebook_size: 256
[DIFF_GRM] masking_strategy: sequential
Traceback (most recent call last):
  File "/share/liuzhao09/diffgm/main.py", line 31, in <module>
    pipeline.run()
  File "/share/liuzhao09/diffgm/genrec/pipeline.py", line 107, in run
    best_epoch, best_val_score = self.trainer.fit(train_dataloader, val_dataloader)
  File "/share/liuzhao09/diffgm/genrec/models/DIFF_GRM/trainer.py", line 104, in fit
    outputs = self.model(batch, return_loss=True)
  File "/root/anaconda3/envs/lz_grm_pd/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/anaconda3/envs/lz_grm_pd/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/liuzhao09/diffgm/genrec/models/DIFF_GRM/model.py", line 573, in forward
    block_output = block(
  File "/root/anaconda3/envs/lz_grm_pd/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/anaconda3/envs/lz_grm_pd/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/liuzhao09/diffgm/genrec/models/DIFF_GRM/model.py", line 170, in forward
    cross_attn_output, cross_present = self.cross_attn(
  File "/root/anaconda3/envs/lz_grm_pd/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/anaconda3/envs/lz_grm_pd/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/liuzhao09/diffgm/genrec/models/DIFF_GRM/model.py", line 80, in forward
    y = torch.matmul(att, v)  # (B, n_head, T, head_dim)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacity of 79.15 GiB of which 325.75 MiB is free. Process 65531 has 47.74 GiB memory in use. Process 84245 has 31.08 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 132.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
